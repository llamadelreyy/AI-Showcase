#!/bin/bash

# Local AI Demo Stack - Quick Start Script
echo "ü§ñ Local AI Demo Stack - Quick Start"
echo "===================================="

# Check if Python is installed
if ! command -v python3 &> /dev/null; then
    echo "‚ùå Python 3 is required but not installed."
    echo "Please install Python 3.8+ and try again."
    exit 1
fi

echo "‚úÖ Python found: $(python3 --version)"

# Check if pip is installed
if ! command -v pip3 &> /dev/null; then
    echo "‚ùå pip3 is required but not installed."
    echo "Please install pip and try again."
    exit 1
fi

echo "‚úÖ pip found"

# Kill any existing processes on port 7860
echo "üîÑ Checking for existing processes on port 7860..."
if lsof -ti:7860 >/dev/null 2>&1; then
    echo "‚ö†Ô∏è Found existing process on port 7860, stopping it..."
    kill -9 $(lsof -ti:7860) 2>/dev/null || true
    sleep 2
fi

# Create virtual environment (optional but recommended)
echo "üì¶ Setting up virtual environment..."
if [ ! -d "venv" ]; then
    python3 -m venv venv
    echo "‚úÖ Virtual environment created"
else
    echo "‚úÖ Virtual environment already exists"
fi

# Activate virtual environment
echo "üîÑ Activating virtual environment..."
source venv/bin/activate

# Upgrade pip
echo "‚¨ÜÔ∏è Upgrading pip..."
pip install --upgrade pip

# Install requirements
echo "üì• Installing requirements (this may take a few minutes)..."
pip install -r requirements.txt

# Check if Ollama is available
echo "ü¶ô Checking for Ollama..."
if command -v ollama &> /dev/null; then
    echo "‚úÖ Ollama found! Checking for models..."
    
    # Check for LLM models
    if ollama list | grep -q "llama2"; then
        echo "‚úÖ Llama2 LLM model found"
    else
        echo "‚ö†Ô∏è No Llama2 model found. You can install it with:"
        echo "   ollama pull llama2:7b-chat"
    fi
    
    # Check for vision models
    if ollama list | grep -q "llava"; then
        echo "‚úÖ LLaVA vision model found"
    else
        echo "üéØ Installing LLaVA vision model for advanced image analysis..."
        echo "   This will enable features like 'Is this a ghost?' questions"
        ollama pull llava:7b
        if [ $? -eq 0 ]; then
            echo "‚úÖ LLaVA vision model installed successfully!"
        else
            echo "‚ö†Ô∏è Failed to install LLaVA. You can install it manually:"
            echo "   ollama pull llava:7b"
        fi
    fi
else
    echo "‚ö†Ô∏è Ollama not found. The app will use local transformers."
    echo "   For better performance and vision features, install Ollama:"
    echo "   curl -fsSL https://ollama.ai/install.sh | sh"
    echo "   ollama pull llama2:7b-chat"
    echo "   ollama pull llava:7b"
fi

echo ""
echo "üéâ Setup complete!"
echo ""
echo "üöÄ Starting Local AI Demo Stack..."
echo "üìù Note: Models will download automatically on first use"
echo "   This may take a few minutes initially."
echo ""
echo "üåê The app will open in your browser automatically"
echo "   If port 7860 is busy, it will find another free port"
echo ""
echo "üéØ Vision Features:"
echo "   - With Ollama LLaVA: Advanced question answering"
echo "   - Ask specific questions like 'Is this a ghost?'"
echo "   - Detailed scene analysis and object recognition"
echo ""
echo "Press Ctrl+C to stop the application"
echo "===================================="

# Start the application
python3 app.py